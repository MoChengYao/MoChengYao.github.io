<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="John Doe"><meta name="renderer" content="webkit"><meta name="copyright" content="John Doe"><meta name="keywords" content="Hexo"><meta name="description" content="null"><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>My First Post · Mr.Long's Blog</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/favicon.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script></head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/cat.png"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">longlongyu</div><div class="profile-signature">for me</div><div class="friends"><div>FRIENDS</div><span><a href="//github.com/Longlongyu" target="_black">friendA</a></span><span><a href="//github.com/" target="_black">friendB</a></span><span><a href="//github.com/" target="_black">friendC</a></span></div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">Mr.Long's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">My First Post</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>2019-04-29</span></span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><h1 id="ngx-http-limit-req-module"><a href="#ngx-http-limit-req-module" class="headerlink" title="ngx_http_limit_req_module"></a>ngx_http_limit_req_module</h1><p>nginx 可以使用 ngx_http_limit_req 模块对 ip 进行限制，其实现方法基于漏桶算法（Leaky Bucket），限制的方式有 每秒固定处理多少请求，推迟多多的请求或者丢弃过多的请求。</p>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>ngx_http_limit_req 使用漏桶算法，该算法有两种处理方式:</p>
<ol>
<li>Traffic Shaping</li>
<li>Traffic Policing</li>
</ol>
<p>拿一个装满水的漏桶举例，如果这个时候，还有水继续往桶里流，我们会有两种处理方式：</p>
<ol>
<li>暂时不让桶外的水流入，等待桶中的水漏掉一部分之后，再让桶外的水的流入桶中</li>
<li>直接丢弃桶外的水</li>
</ol>
<p>换种说法，例子中的水可以看作请求数，漏桶可以看作 nginx 可以容纳的请求数，如果 nginx 的请求数已经达到最大值，此时又有新的请求发送到 nginx 这边，nginx 如果先处理已经进来的请求数，等消化完一部分请求数再接受新的请求数，这样的处理方式就是例子中的第一种方式，也就是 Traffic Shaping。如果直接拒绝了新的请求，这样的处理方式就是例子中的第二种方式，也就是 Traffic Policing。</p>
<p>总的来说，Traffic Shaping 是会处理所有请求的，只不过会延迟处理而已。而 Traffic Policing 只会处理已接受的请求，丢弃所有新的请求。</p>
<h3 id="配置指令"><a href="#配置指令" class="headerlink" title="配置指令"></a>配置指令</h3><h4 id="配置模板"><a href="#配置模板" class="headerlink" title="配置模板"></a>配置模板</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s;</span><br><span class="line">    ...</span><br><span class="line">    server &#123;</span><br><span class="line">        ...</span><br><span class="line">        location /search/ &#123;</span><br><span class="line">            limit_req zone=one burst=5 nodelay;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<h4 id="limit-req-zone"><a href="#limit-req-zone" class="headerlink" title="limit_req_zone"></a>limit_req_zone</h4><table>
<thead>
<tr>
<th>Syntax</th>
<th>limit_req_zone key zone=name:size rate=rate;</th>
</tr>
</thead>
<tbody>
<tr>
<td>Default</td>
<td>none</td>
</tr>
<tr>
<td>Context</td>
<td>http</td>
</tr>
</tbody>
</table>
<p>该指令用来分配一块名为 name ，大小为 size 的共享内存，这块共享内存服务于一个特定的 key，限制了请求频率不得超过 rate。若超过了频率，则会有两种处理方式，具体是等待，还是丢弃，取决于 limit_req 的配置。</p>
<p>对应模板的 limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; 就是：分配一个名为 one，大小为 10m 的共享内存，这块共享内存服务于二进制的请求 ip，如果该二进制的请求 ip 的请求频率超过了 1r/s，也就是一秒一次。由于我在后面 limit_req 配置了 burst 和 nodelay，所以会先有 5 个请求进入缓存，没过 1s 依次处理缓存中的请求，剩下的全部丢弃。</p>
<p>这里得提个问题，为什么 key 配置为 $binary_remote_addr 而不是 $remote_addr，难道是因为 $remote_addr 变量的长度为 7 字节到 15 字节，而 $binary_remote_addr 变量的长度是固定的 4 字节，为了节省不多的共享内存空间才使用的。但是这两者的变量的存储状态都是一致的，即在32位平台中占用32字节或64字节，在64位平台中占用64字节。难道是变量的长度跟存储长度是不对等的？这个晚点再研究一下</p>
<p>顺带提一下一个潜在的坑，如果共享内存被用光，nginx 会对后续的所有请求返回 503(Service Temporarily Unavailable) 错误，为什么是 503 错误，是因为该模块返回的错误默认是 503，这个在后续的 limit_req_status 里面会谈到。也就是说，如果共享内存被用光，nginx 先消化清除一些最近最少使用的状态，来达到可以接受新请求的目的，这一点类似于 gc。但是在类 gc 的过程中，nginx 会对所有的新请求进行丢弃操作，即使你的请求次数没有超过频率，但还是返回 503 错误。这个得提防一下。</p>
<h4 id="limit-req"><a href="#limit-req" class="headerlink" title="limit_req"></a>limit_req</h4><table>
<thead>
<tr>
<th>Syntax</th>
<th>limit_req zone=name [burst=number] [nodelay];</th>
</tr>
</thead>
<tbody>
<tr>
<td>Default</td>
<td>none</td>
</tr>
<tr>
<td>Context</td>
<td>http, server, location</td>
</tr>
</tbody>
</table>
<p>该指令为 名为 name 的共享内存设置一个突发请求限制大小（burst）和一个 nodelay 标志位。</p>
<p>因为我们在 limit_req_zone 里面配置了访问频率，但是有时候又会遇见爆发式的 ip 访问，这个时候， burst 参数就可以帮我们应对这样的场景， burst 可以配置一个突发请求数量，也就是说，虽然我们在 limit_req_zone 里面配置访问频率，但是如果我们在 limit_req 里面配置了 burst ，nginx 是可以在单位时间内先接受 burst 个请求，让其在队列里面排队，而不是直接丢弃。即将爆发的请求放入一个缓冲区。</p>
<p>还有一种情况，当访问的请求 ip 超出了 burst 的数量。比如说，我设置rate-1r/s  burst=5，现在有 10 个爆发式请求过来，但是 burst 只能容纳 5 个请求，这就意味着剩下 5 个请求在队列外边排队，在他们排队结束之后，等待他们的 nginx 的丢弃，因为我们配置了一秒只能接受一个请求，可以容纳 5 个爆发式的请求。为了让未进入队列的 5 个请求不会白白排队，我们就需要设置 nodelay 参数。nodelay 参数可以给那些溢出 burst 的请求直接返回 503，使其不会白白排队。</p>
<h4 id="limit-req-log-level"><a href="#limit-req-log-level" class="headerlink" title="limit_req_log_level"></a>limit_req_log_level</h4><table>
<thead>
<tr>
<th>Syntax</th>
<th>limit_req_log_level （info or notice or warn or error）</th>
</tr>
</thead>
<tbody>
<tr>
<td>Default</td>
<td>error</td>
</tr>
<tr>
<td>Context</td>
<td>http, server, location</td>
</tr>
</tbody>
</table>
<p>limit_req_log_level 这条指令用来设置当触发请求限制时，记录日志的级别，默认是 error</p>
<h4 id="limit-req-status"><a href="#limit-req-status" class="headerlink" title="limit_req_status"></a>limit_req_status</h4><table>
<thead>
<tr>
<th>Syntax</th>
<th>limit_req_status code;</th>
</tr>
</thead>
<tbody>
<tr>
<td>Default</td>
<td>limit_req_status 503</td>
</tr>
<tr>
<td>Context</td>
<td>http, server, location</td>
</tr>
</tbody>
</table>
<p>limit_req_status 用来设置服务器因请求限制设置而拒绝一个请求时，返回的状态码，默认是 503</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="实验样例"><a href="#实验样例" class="headerlink" title="实验样例"></a>实验样例</h4><p>实验分三种样例，分别是：</p>
<ol>
<li>单测试 rate</li>
<li>测试 rate 和 burst</li>
<li>测试 rete 和 burst 和 nodelay</li>
</ol>
<h4 id="实验相关参数"><a href="#实验相关参数" class="headerlink" title="实验相关参数"></a>实验相关参数</h4><table>
<thead>
<tr>
<th>python</th>
<th>3</th>
</tr>
</thead>
<tbody>
<tr>
<td>nginx</td>
<td>1.8.0</td>
</tr>
<tr>
<td>线程数量</td>
<td>10</td>
</tr>
<tr>
<td>rate</td>
<td>2r/s</td>
</tr>
<tr>
<td>burst</td>
<td>2</td>
</tr>
</tbody>
</table>
<h4 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import time,requests</span><br><span class="line"># 使用 tomorrow 模块快速创建多线程访问</span><br><span class="line">from tomorrow import threads</span><br><span class="line"># 设置多线程数量</span><br><span class="line">number = 5</span><br><span class="line">@threads(number)</span><br><span class="line">def goto_url(url):</span><br><span class="line">    try:</span><br><span class="line">        return requests.get(url)</span><br><span class="line">    except:</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = &apos;http://10.17.2.192&apos;</span><br><span class="line">urls = [url for i in range(number)]</span><br><span class="line">start = time.time()</span><br><span class="line"># 多线程访问网页</span><br><span class="line">responses = [goto_url(url) for url in urls]</span><br><span class="line"># end = time.time()</span><br><span class="line"># 获取多线程访问的状态码</span><br><span class="line">code = [response.status_code for response in responses if hasattr(response,&quot;status_code&quot;)]</span><br><span class="line"># 获取多线程访问网页的请求时间</span><br><span class="line">microseconds = [response.elapsed.microseconds/1000 for response in responses if hasattr(response,&quot;elapsed&quot;)]</span><br><span class="line"></span><br><span class="line">count = 0</span><br><span class="line">while count &lt; number:</span><br><span class="line">    print(&quot;status code : &#123;&#125; , nginx response time : &#123;&#125; ms&quot;.format(code[count],microseconds[count]))</span><br><span class="line">    count += 1</span><br><span class="line">print(&apos;now, sleep 500 ms&apos;)</span><br><span class="line">time.sleep(0.5)</span><br><span class="line"># start = time.time()</span><br><span class="line"># 多线程访问网页</span><br><span class="line">responses = [goto_url(url) for url in urls]</span><br><span class="line">end = time.time()</span><br><span class="line"># 获取多线程访问的状态码</span><br><span class="line">code = [response.status_code for response in responses if hasattr(response,&quot;status_code&quot;)]</span><br><span class="line"># 获取多线程访问网页的请求时间</span><br><span class="line">microseconds = [response.elapsed.microseconds/1000 for response in responses if hasattr(response,&quot;elapsed&quot;)]</span><br><span class="line"></span><br><span class="line">count = 0</span><br><span class="line">while count &lt; number:</span><br><span class="line">    print(&quot;status code : &#123;&#125; , nginx response time : &#123;&#125; ms&quot;.format(code[count],microseconds[count]))</span><br><span class="line">    count += 1</span><br><span class="line"># 输出多线程访问网页的运行时间</span><br><span class="line">all = (end - start)* 1000</span><br><span class="line">print (&quot;Time: %f ms&quot; % (all))</span><br></pre></td></tr></table></figure>
<p>在代码中，我先发送了 5 个请求，然后休眠了半秒，之后继续发送 5 个请求。</p>
<h4 id="样例一"><a href="#样例一" class="headerlink" title="样例一"></a>样例一</h4><p>nginx 配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">	………………</span><br><span class="line">    limit_req_zone $remote_addr zone=one:10m rate=2r/s;</span><br><span class="line">    server &#123;</span><br><span class="line"></span><br><span class="line">        limit_req zone=one;</span><br></pre></td></tr></table></figure></p>
<p>实验结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">status code : 200 , nginx response time : 10.518 ms</span><br><span class="line">status code : 503 , nginx response time : 7.179 ms</span><br><span class="line">status code : 503 , nginx response time : 8.869 ms</span><br><span class="line">status code : 503 , nginx response time : 6.959 ms</span><br><span class="line">status code : 503 , nginx response time : 4.553 ms</span><br><span class="line">now, sleep 500 ms</span><br><span class="line">status code : 200 , nginx response time : 17.672 ms</span><br><span class="line">status code : 503 , nginx response time : 15.863 ms</span><br><span class="line">status code : 503 , nginx response time : 13.522 ms</span><br><span class="line">status code : 503 , nginx response time : 11.187 ms</span><br><span class="line">status code : 503 , nginx response time : 10.092 ms</span><br><span class="line">Time: 522.355080 ms</span><br></pre></td></tr></table></figure></p>
<p>从结果来看，前 5 次请求中，只有一个请求是成功，剩余 4 个都是失败的。为什么会出现这种情况呢？看了第二次的 5 次请求就明白了。因为我们设置了 rate=2r/s，也就是一秒可以接受两个请求，换算一下，也就是每半秒接受一个请求，也就是 500ms 接受一个请求，也就是在 0 - 500ms 这段时间内，只能接受一个请求，从 501ms 开始，才可以接受第二个请求。将上面代码的休眠时间改成 0.4s，也就是休眠 400ms，第二次的访问的结果都是 503</p>
<h4 id="样例二"><a href="#样例二" class="headerlink" title="样例二"></a>样例二</h4><p>nginx 配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">	………………</span><br><span class="line">    limit_req_zone $remote_addr zone=one:10m rate=2r/s;</span><br><span class="line">    server &#123;</span><br><span class="line"></span><br><span class="line">        limit_req zone=one burst=2;</span><br></pre></td></tr></table></figure></p>
<p>实验结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">status code : 200 , nginx response time : 13.219 ms</span><br><span class="line">status code : 200 , nginx response time : 9.892 ms</span><br><span class="line">status code : 200 , nginx response time : 508.075 ms</span><br><span class="line">status code : 503 , nginx response time : 4.55 ms</span><br><span class="line">status code : 503 , nginx response time : 2.609 ms</span><br><span class="line">now, sleep 500 ms</span><br><span class="line">status code : 200 , nginx response time : 18.257 ms</span><br><span class="line">status code : 200 , nginx response time : 14.568 ms</span><br><span class="line">status code : 200 , nginx response time : 511.585 ms</span><br><span class="line">status code : 503 , nginx response time : 9.829 ms</span><br><span class="line">status code : 503 , nginx response time : 7.876 ms</span><br><span class="line">Time: 1523.109198 ms</span><br></pre></td></tr></table></figure></p>
<p>从结果上看，我分开两次的 5 个请求均成功了 3 次，失败了 2 次。为什么会这样呢？我 burst 设置的不是 2 吗，为什么还会成功 3 次。因为 burst 只是设置允许存储爆发式的请求 ip，在实验中，我一次发起了 5 次请求，nginx 每 500ms 可以处理 1 个请求，剩下四个请求中，由于我们的缓冲队列只设置为 2，所有只有两个请求进入了缓冲队列，剩下两个请求则在队列之后排队。进入队列的请求在 nginx 处理完第一个请求之后，依次处理。由于 burst 设置为 2，这就直接导致 nginx 在处理完队列里面的两个请求之后，直接给队列之后的两个请求返回 503 的错误。</p>
<h4 id="样例三"><a href="#样例三" class="headerlink" title="样例三"></a>样例三</h4><p>nginx 配置如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">	………………</span><br><span class="line">    limit_req_zone $remote_addr zone=one:10m rate=2r/s;</span><br><span class="line">    server &#123;</span><br><span class="line"></span><br><span class="line">        limit_req zone=one burst=2 nodelay;</span><br></pre></td></tr></table></figure></p>
<p>实验结果：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">status code : 200 , nginx response time : 14.092 ms</span><br><span class="line">status code : 200 , nginx response time : 15.813 ms</span><br><span class="line">status code : 200 , nginx response time : 14.509 ms</span><br><span class="line">status code : 503 , nginx response time : 9.306 ms</span><br><span class="line">status code : 503 , nginx response time : 7.332 ms</span><br><span class="line">now, sleep 500 ms</span><br><span class="line">status code : 200 , nginx response time : 10.285 ms</span><br><span class="line">status code : 503 , nginx response time : 19.848 ms</span><br><span class="line">status code : 503 , nginx response time : 13.92 ms</span><br><span class="line">status code : 503 , nginx response time : 6.382 ms</span><br><span class="line">status code : 503 , nginx response time : 8.915 ms</span><br><span class="line">Time: 534.612656 ms</span><br></pre></td></tr></table></figure></p>
<p>从实验结果上看，相比样例二，总体时间也减少了很多，这都是得益于 nodelay 参数，让 nginx 对未进入队列的请求直接返回了 503 的错误，直接跳过了等待时间。</p>
<p>不过也产生了新的问题，但看第一次的 5 个请求，结果还是颇为满意的，但是第二次的 5 个请求就有点差强人意了，按道理来说，5 次请求应该会成功 3 次，但是却只成功了 1 次。</p>
<p>这个就跟 nginx 的队列有关系了。由于我们设置了 nodelay 参数，当队列满的情况下， nginx 会给那些未进入队列的请求直接返回 503，但是我们的 nginx 被设置为每 500ms 只能处理 1 个请求，所以在第一个 500ms 里，nginx 处理了一个请求，将紧接的两个请求塞进了队列，给最后两个请求返回了 503 错误，nginx 处理了第一个请求之后，程序休眠 500ms，进入了第二个 500ms，nginx 看见队列里面还有请求尚未处理，开始处理队列中的第一个请求，此时，队列空出了一个位置，紧接着，我们又发起了 5 个请求，但是因为队列只剩余一个空位，所有只有一个请求进入了队列，剩余四个请求则被 nginx 直接返回了 503 的错误。</p>
<p>总的来说，因为我们同时设置了 burst 和 nodelay 的参数，导致 nginx 会给未进入队列的请求返回 503，nginx 会按照我们设置的频率依次处理请求，将队列空出来，容纳即将到来的请求</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上便是我对 ngx_http_limit_req 的一些拙见和笔记，研究的浅，若有什么错误，还望海涵。</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p><a href="http://ningning.today/2016/01/22/python/python%E7%94%A8%E8%A3%85%E9%A5%B0%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%BA%BF%E7%A8%8B/" target="_blank" rel="noopener">python用装饰器实现多线程</a><br><a href="http://blog.topspeedsnail.com/archives/7875" target="_blank" rel="noopener">限制Nginx的请求频率</a><br><a href="https://cloud.tencent.com/developer/section/1259210" target="_blank" rel="noopener">ngx_http_limit_req_module</a><br><a href="https://www.jianshu.com/p/f9888812e89c" target="_blank" rel="noopener">nginx服务器请求限制模块（ngx_http_limit_req_module）</a><br><a href="https://segmentfault.com/a/1190000007930671" target="_blank" rel="noopener">ngx_http_limit_req_module 源码分析</a><br><a href="https://yq.aliyun.com/articles/310403?utm_content=m_38226" target="_blank" rel="noopener">Nginx限速模块初探</a><br><a href="http://www.ttlsa.com/nginx/nginx-limiting-the-number-of-requests-ngx_http_limit_req_module-module/" target="_blank" rel="noopener">nginx限制请求数ngx_http_limit_req_module模块</a><br><a href="https://www.chrisyue.com/leaky-bucket-and-nginx-limit_req-module.html" target="_blank" rel="noopener">漏桶算法和 NGINX 的 limit_req 模块</a><br><a href="https://www.nginx.com/blog/rate-limiting-nginx/" target="_blank" rel="noopener">Rate Limiting with NGINX and NGINX Plus</a></p>
</article><!-- lincense--><div class="license-wrapper"><p> <span>Author:  </span><a href="http://10.17.2.191">John Doe</a></p><p> <span>Link:  </span><a href="http://10.17.2.191/2019/04/29/My-First-Post/">http://10.17.2.191/2019/04/29/My-First-Post/</a></p><p> <span>Copyright:  </span><span>All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/3.0">CC BY-NC-SA 3.0</a> unless stating additionally.</span></p></div><div class="post-paginator"><a class="nextSlogan" href="/2019/04/29/hello-world/" title="Hello World"><span>NextPost ></span><br><span class="nextTitle">Hello World</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#ngx-http-limit-req-module"><span class="toc-number">1.</span> <span class="toc-text">ngx_http_limit_req_module</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#原理"><span class="toc-number">1.0.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#配置指令"><span class="toc-number">1.0.2.</span> <span class="toc-text">配置指令</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#配置模板"><span class="toc-number">1.0.2.1.</span> <span class="toc-text">配置模板</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#limit-req-zone"><span class="toc-number">1.0.2.2.</span> <span class="toc-text">limit_req_zone</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#limit-req"><span class="toc-number">1.0.2.3.</span> <span class="toc-text">limit_req</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#limit-req-log-level"><span class="toc-number">1.0.2.4.</span> <span class="toc-text">limit_req_log_level</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#limit-req-status"><span class="toc-number">1.0.2.5.</span> <span class="toc-text">limit_req_status</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验"><span class="toc-number">1.0.3.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#实验样例"><span class="toc-number">1.0.3.1.</span> <span class="toc-text">实验样例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实验相关参数"><span class="toc-number">1.0.3.2.</span> <span class="toc-text">实验相关参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实验代码"><span class="toc-number">1.0.3.3.</span> <span class="toc-text">实验代码</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#样例一"><span class="toc-number">1.0.3.4.</span> <span class="toc-text">样例一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#样例二"><span class="toc-number">1.0.3.5.</span> <span class="toc-text">样例二</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#样例三"><span class="toc-number">1.0.3.6.</span> <span class="toc-text">样例三</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-number">1.0.4.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#参考链接"><span class="toc-number">1.0.5.</span> <span class="toc-text">参考链接</span></a></li></ol></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>